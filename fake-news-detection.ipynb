{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13491384,"sourceType":"datasetVersion","datasetId":8565929}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers==4.36.2 peft==0.9.0 accelerate==0.25.0\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:47.199668Z","iopub.execute_input":"2025-10-25T05:50:47.200218Z","iopub.status.idle":"2025-10-25T05:50:50.656955Z","shell.execute_reply.started":"2025-10-25T05:50:47.200184Z","shell.execute_reply":"2025-10-25T05:50:50.656178Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:50.658377Z","iopub.execute_input":"2025-10-25T05:50:50.658622Z","iopub.status.idle":"2025-10-25T05:50:50.663164Z","shell.execute_reply.started":"2025-10-25T05:50:50.658603Z","shell.execute_reply":"2025-10-25T05:50:50.662636Z"}},"outputs":[{"name":"stdout","text":"4.36.2\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Dataset Initialization and Preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/truth-seeker-model/Truth_Seeker_Model_Dataset.csv')\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:50.663831Z","iopub.execute_input":"2025-10-25T05:50:50.663992Z","iopub.status.idle":"2025-10-25T05:50:51.303939Z","shell.execute_reply.started":"2025-10-25T05:50:50.663980Z","shell.execute_reply":"2025-10-25T05:50:51.303139Z"}},"outputs":[{"name":"stdout","text":"   Unnamed: 0      author                                          statement  \\\n0           0  D.L. Davis  End of eviction moratorium means millions of A...   \n1           1  D.L. Davis  End of eviction moratorium means millions of A...   \n2           2  D.L. Davis  End of eviction moratorium means millions of A...   \n3           3  D.L. Davis  End of eviction moratorium means millions of A...   \n4           4  D.L. Davis  End of eviction moratorium means millions of A...   \n\n   target  BinaryNumTarget                 manual_keywords  \\\n0    True              1.0  Americans, eviction moratorium   \n1    True              1.0  Americans, eviction moratorium   \n2    True              1.0  Americans, eviction moratorium   \n3    True              1.0  Americans, eviction moratorium   \n4    True              1.0  Americans, eviction moratorium   \n\n                                               tweet 5_label_majority_answer  \\\n0  @POTUS Biden Blunders - 6 Month Update\\n\\nInfl...            Mostly Agree   \n1  @S0SickRick @Stairmaster_ @6d6f636869 Not as m...             NO MAJORITY   \n2  THE SUPREME COURT is siding with super rich pr...                   Agree   \n3  @POTUS Biden Blunders\\n\\nBroken campaign promi...            Mostly Agree   \n4  @OhComfy I agree. The confluence of events rig...                   Agree   \n\n  3_label_majority_answer  \n0                   Agree  \n1                   Agree  \n2                   Agree  \n3                   Agree  \n4                   Agree  \n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(df['BinaryNumTarget'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:51.305513Z","iopub.execute_input":"2025-10-25T05:50:51.305773Z","iopub.status.idle":"2025-10-25T05:50:51.312646Z","shell.execute_reply.started":"2025-10-25T05:50:51.305756Z","shell.execute_reply":"2025-10-25T05:50:51.311956Z"}},"outputs":[{"name":"stdout","text":"BinaryNumTarget\n1.0    68930\n0.0    65268\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Remove URLs\n    text = re.sub(r\"@\\w+\", \"\", text)           # Remove mentions\n    text = re.sub(r\"#\", \"\", text)              # Remove hashtag symbol\n    text = re.sub(r\"[^A-Za-z0-9\\s]\", \"\", text) # Remove special characters\n    text = text.strip()\n    return text\n\ndf['tweet'] = df['tweet'].apply(clean_text)\n\n# Check first few cleaned tweets\nprint(df['tweet'].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:51.313442Z","iopub.execute_input":"2025-10-25T05:50:51.313673Z","iopub.status.idle":"2025-10-25T05:50:52.478483Z","shell.execute_reply.started":"2025-10-25T05:50:51.313658Z","shell.execute_reply":"2025-10-25T05:50:52.477790Z"}},"outputs":[{"name":"stdout","text":"0    Biden Blunders  6 Month Update\\n\\nInflation De...\n1    Not as many people are literally starving and ...\n2    THE SUPREME COURT is siding with super rich pr...\n3    Biden Blunders\\n\\nBroken campaign promises Inf...\n4    I agree The confluence of events right now is ...\nName: tweet, dtype: object\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['tweet'].tolist(),\n    df['BinaryNumTarget'].tolist(),\n    test_size=0.1,           # 10% for validation\n    random_state=42,\n    stratify=df['BinaryNumTarget']  # Keep the label distribution balanced\n)\n\nprint(f\"Training samples: {len(train_texts)}, Validation samples: {len(val_texts)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:52.479396Z","iopub.execute_input":"2025-10-25T05:50:52.479688Z","iopub.status.idle":"2025-10-25T05:50:52.584098Z","shell.execute_reply.started":"2025-10-25T05:50:52.479664Z","shell.execute_reply":"2025-10-25T05:50:52.583345Z"}},"outputs":[{"name":"stdout","text":"Training samples: 120778, Validation samples: 13420\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\n\n# Tokenize the training and validation texts\ntrain_encodings = tokenizer(\n    train_texts,\n    truncation=True,\n    padding=True,\n    max_length=128\n)\n\nval_encodings = tokenizer(\n    val_texts,\n    truncation=True,\n    padding=True,\n    max_length=128\n)\n\n# Inspect one example\nprint(train_encodings['input_ids'][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:50:52.584949Z","iopub.execute_input":"2025-10-25T05:50:52.585329Z","iopub.status.idle":"2025-10-25T05:51:04.722249Z","shell.execute_reply.started":"2025-10-25T05:50:52.585283Z","shell.execute_reply":"2025-10-25T05:51:04.721367Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[0, 100, 40, 45, 3568, 10, 11445, 5, 200, 86, 198, 7632, 54, 34, 45, 5335, 26999, 40, 45, 109, 24, 38, 33, 26999, 142, 38, 109, 679, 2866, 635, 187, 38, 33, 5335, 26999, 38, 109, 45, 240, 7, 3568, 10, 11445, 166, 240, 7, 912, 42, 20175, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import torch\n\nclass NewsDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n# Create training and validation datasets\ntrain_dataset = NewsDataset(train_encodings, train_labels)\nval_dataset = NewsDataset(val_encodings, val_labels)\n\n# Check the first example\nprint(train_dataset[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:51:04.723193Z","iopub.execute_input":"2025-10-25T05:51:04.723575Z","iopub.status.idle":"2025-10-25T05:51:04.732233Z","shell.execute_reply.started":"2025-10-25T05:51:04.723545Z","shell.execute_reply":"2025-10-25T05:51:04.731498Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([    0,   100,    40,    45,  3568,    10, 11445,     5,   200,    86,\n          198,  7632,    54,    34,    45,  5335, 26999,    40,    45,   109,\n           24,    38,    33, 26999,   142,    38,   109,   679,  2866,   635,\n          187,    38,    33,  5335, 26999,    38,   109,    45,   240,     7,\n         3568,    10, 11445,   166,   240,     7,   912,    42, 20175,     2,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n            1,     1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(0.)}\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\n# Load roberta-base with 2 labels (Fake/Real)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    'roberta-base',\n    num_labels=2\n)\n\nimport torch\nif torch.cuda.is_available():\n    model.to('cuda')\nelse:\n    print(\"⚠️ CUDA not available, running on CPU\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:51:04.732965Z","iopub.execute_input":"2025-10-25T05:51:04.733135Z","iopub.status.idle":"2025-10-25T05:51:05.285759Z","shell.execute_reply.started":"2025-10-25T05:51:04.733121Z","shell.execute_reply":"2025-10-25T05:51:05.284962Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.config.problem_type = \"single_label_classification\"  # must be single-label\nbatch['labels'] = batch['labels'].long()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T05:59:42.440504Z","iopub.execute_input":"2025-10-25T05:59:42.441135Z","iopub.status.idle":"2025-10-25T05:59:42.444800Z","shell.execute_reply.started":"2025-10-25T05:59:42.441111Z","shell.execute_reply":"2025-10-25T05:59:42.443946Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom transformers import AdamW\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom tqdm import tqdm\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=8)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\n# Training parameters\nnum_epochs = 3\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Force correct problem type\nmodel.config.problem_type = \"single_label_classification\"\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        optimizer.zero_grad()\n        batch = {k: v.to(device) for k, v in batch.items()}\n        batch['labels'] = batch['labels'].long()  # important for CrossEntropyLoss\n\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        loop.set_description(f\"Epoch {epoch+1}\")\n        loop.set_postfix(batch_loss=loss.item())\n\n    avg_train_loss = train_loss / len(train_loader)\n\n    # ===== Validation =====\n    model.eval()\n    val_loss = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            batch['labels'] = batch['labels'].long()\n            outputs = model(**batch)\n            loss = outputs.loss\n            val_loss += loss.item()\n\n            preds = torch.argmax(outputs.logits, dim=1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(batch['labels'].cpu().numpy())\n\n    avg_val_loss = val_loss / len(val_loader)\n    val_acc = accuracy_score(all_labels, all_preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n\n    print(f\"\\nEpoch {epoch+1} summary:\")\n    print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n    print(f\"Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T06:02:54.219552Z","iopub.execute_input":"2025-10-25T06:02:54.219826Z","iopub.status.idle":"2025-10-25T08:45:34.296294Z","shell.execute_reply.started":"2025-10-25T06:02:54.219808Z","shell.execute_reply":"2025-10-25T08:45:34.295522Z"}},"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 15098/15098 [52:32<00:00,  4.79it/s, batch_loss=0.00112] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 summary:\nTrain Loss: 0.0951 | Val Loss: 0.0627 | Val Acc: 0.9805\nPrecision: 0.9684 | Recall: 0.9945 | F1-score: 0.9812\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 15098/15098 [52:32<00:00,  4.79it/s, batch_loss=0.0278]  \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 summary:\nTrain Loss: 0.0413 | Val Loss: 0.0392 | Val Acc: 0.9879\nPrecision: 0.9826 | Recall: 0.9939 | F1-score: 0.9882\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 15098/15098 [52:31<00:00,  4.79it/s, batch_loss=0.774]   \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 summary:\nTrain Loss: 0.0279 | Val Loss: 0.0449 | Val Acc: 0.9881\nPrecision: 0.9818 | Recall: 0.9952 | F1-score: 0.9885\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel.to(device)\nmodel.eval()  # Set model to evaluation mode\n\nall_preds = []\nall_labels = []\nval_loss = 0\nloss_fn = torch.nn.CrossEntropyLoss()  # For binary classification with logits\n\nwith torch.no_grad():\n    for batch in val_loader:\n        # Move batch to GPU\n        batch = {k: v.to(device) for k, v in batch.items()}\n        batch['labels'] = batch['labels'].long()  # convert to long\n        outputs = model(**batch)\n\n        \n        # Forward pass\n        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n        loss = outputs.loss\n        val_loss += loss.item()\n        \n        # Get predictions\n        preds = torch.argmax(outputs.logits, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(batch['labels'].cpu().numpy())\n\n# Compute average loss\nval_loss /= len(val_loader)\n\n# Compute metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n\nprint(f\"Validation Loss: {val_loss:.4f}\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T09:14:39.499606Z","iopub.execute_input":"2025-10-25T09:14:39.500279Z","iopub.status.idle":"2025-10-25T09:17:41.111933Z","shell.execute_reply.started":"2025-10-25T09:14:39.500256Z","shell.execute_reply":"2025-10-25T09:17:41.111242Z"}},"outputs":[{"name":"stdout","text":"Validation Loss: 0.0449\nAccuracy: 0.9881\nPrecision: 0.9818, Recall: 0.9952, F1-score: 0.9885\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"# Saving the Model","metadata":{}},{"cell_type":"code","source":"# Save model\nmodel_save_path = '/kaggle/working/roberta-fake-news-model'\nmodel.save_pretrained(model_save_path)\n\n# Save tokenizer\ntokenizer.save_pretrained(model_save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T08:50:55.594716Z","iopub.execute_input":"2025-10-25T08:50:55.595026Z","iopub.status.idle":"2025-10-25T08:50:56.775590Z","shell.execute_reply.started":"2025-10-25T08:50:55.595008Z","shell.execute_reply":"2025-10-25T08:50:56.774876Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/roberta-fake-news-model/tokenizer_config.json',\n '/kaggle/working/roberta-fake-news-model/special_tokens_map.json',\n '/kaggle/working/roberta-fake-news-model/vocab.json',\n '/kaggle/working/roberta-fake-news-model/merges.txt',\n '/kaggle/working/roberta-fake-news-model/added_tokens.json',\n '/kaggle/working/roberta-fake-news-model/tokenizer.json')"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"import shutil\n\n# Path to the saved model folder\nmodel_folder = '/kaggle/working/roberta-fake-news-model'\nzip_path = '/kaggle/working/roberta-fake-news-model.zip'\n\n# Zip the folder\nshutil.make_archive(base_name=zip_path.replace('.zip',''), format='zip', root_dir=model_folder)\n\nprint(f\"Model zipped at: {zip_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T08:51:59.116487Z","iopub.execute_input":"2025-10-25T08:51:59.116751Z","iopub.status.idle":"2025-10-25T08:52:26.872833Z","shell.execute_reply.started":"2025-10-25T08:51:59.116733Z","shell.execute_reply":"2025-10-25T08:52:26.872063Z"}},"outputs":[{"name":"stdout","text":"Model zipped at: /kaggle/working/roberta-fake-news-model.zip\n","output_type":"stream"}],"execution_count":34}]}